<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Santiago|Rentería</title>
    <description>Bio-Computer Scientist | Creative Developer</description>
    <link>http://localhost:4000/renterialab.com/</link>
    <atom:link href="http://localhost:4000/renterialab.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 07 Jun 2020 22:57:00 -0500</pubDate>
    <lastBuildDate>Sun, 07 Jun 2020 22:57:00 -0500</lastBuildDate>
    <generator>Jekyll v4.1.0</generator>
    
      <item>
        <title>The Impact of Melody on Short-term Memory</title>
        <description>&lt;p&gt;During the class of Music and psychoacoustics I studied with my team the impact of melodic components in memory. For this purpose we conducted two experiments: The first one consisted in studying the effects of melody in short term memory by evaluating the recall of sung and spoken letter sequences. The second used two groups of sung melodies (structured and chaotic) to study how the regularity of melodic and rhythmic features impacts memorization. Both experiments were carried out with students between 12 and 16 years old. The following video explains the results and methodology in detail.&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe src=&quot;https://www.youtube.com/embed/UvXIP1s1dFc&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
        <pubDate>Fri, 01 Dec 2017 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/renterialab.com/research/music_memory.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/research/music_memory.html</guid>
        
        <category>Cognitive Science</category>
        
        <category>Memory</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Recording and Mixing</title>
        <description>&lt;p&gt;Thanks to the class of Music Production and Recording Techniques I had the opportunity to collaborate with various musicians and learn from &lt;a href=&quot;https://www.linkedin.com/in/juan-switalski-9407ba89/&quot;&gt;Juan Switalski&lt;/a&gt;, a friend and talented recording engineer.&lt;/p&gt;

&lt;h1 id=&quot;orchestra-recording&quot;&gt;Orchestra recording&lt;/h1&gt;

&lt;p&gt;Recording and mixing of Escuela Superior de Música Orchestra at Centro Cultural Coyoacanense.&lt;/p&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;265&quot; src=&quot;https://clyp.it/3kqia1ke/widget&quot; frameborder=&quot;0&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Decca Tree and AB Recording Techniques&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/recording/orchestra_3.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;AKG 414 Mic&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/recording/orchestra_1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;Juan Switalski and some colleagues&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/recording/orchestra_2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;h1 id=&quot;studio-recording&quot;&gt;Studio recording&lt;/h1&gt;

&lt;h2 id=&quot;the-risin-sun&quot;&gt;The Risin’ Sun&lt;/h2&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;166&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; allow=&quot;autoplay&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/351166960&amp;amp;color=ff5500&quot;&gt;&lt;/iframe&gt;
&lt;div style=&quot;font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;&quot;&gt;&lt;a href=&quot;https://soundcloud.com/santiagorenteria&quot; title=&quot;SantiagoRenteria&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt; SantiagoRenteria&lt;/a&gt; &lt;a href=&quot;https://soundcloud.com/santiagorenteria/the-ballad-of-being-a-man-the-risin-sun&quot; title=&quot;The Ballad (of Being A Man) - The Risin Sun&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt;The Ballad (of Being A Man) - The Risin Sun&lt;/a&gt;&lt;/div&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/recording/rising_sun.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;h2 id=&quot;why-dont-you-do-right-peggy-lee-cover&quot;&gt;Why don’t you do right (Peggy Lee Cover)&lt;/h2&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;166&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; allow=&quot;autoplay&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/351168049&amp;amp;color=ff5500&quot;&gt;&lt;/iframe&gt;
&lt;div style=&quot;font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;&quot;&gt;&lt;a href=&quot;https://soundcloud.com/santiagorenteria&quot; title=&quot;SantiagoRenteria&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt;SantiagoRenteria&lt;/a&gt; · &lt;a href=&quot;https://soundcloud.com/santiagorenteria/why-dont-you-do-right-peggy-lee-cover&quot; title=&quot;Why don’t you do right - Peggy Lee (Cover)&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt;Why don’t you do right - Peggy Lee (Cover)&lt;/a&gt;&lt;/div&gt;

&lt;h1 id=&quot;binaural-recording&quot;&gt;Binaural Recording&lt;/h1&gt;

&lt;p&gt;Please use headphones for best experience.&lt;/p&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;166&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; allow=&quot;autoplay&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/351169774&amp;amp;color=ff5500&quot;&gt;&lt;/iframe&gt;
&lt;div style=&quot;font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;&quot;&gt;&lt;a href=&quot;https://soundcloud.com/santiagorenteria&quot; title=&quot;SantiagoRenteria&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt;SantiagoRenteria&lt;/a&gt; · &lt;a href=&quot;https://soundcloud.com/santiagorenteria/acoustic-intro-live-binaural-recording-contemporary-guitar-ensemble&quot; title=&quot;Acoustic Intro. (Live Binaural Recording) - Contemporary Guitar Ensemble&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt;Acoustic Intro. (Live Binaural Recording) - Contemporary Guitar Ensemble&lt;/a&gt;&lt;/div&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;166&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; allow=&quot;autoplay&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/351169282&amp;amp;color=ff5500&quot;&gt;&lt;/iframe&gt;
&lt;div style=&quot;font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;&quot;&gt;&lt;a href=&quot;https://soundcloud.com/santiagorenteria&quot; title=&quot;SantiagoRenteria&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt;SantiagoRenteria&lt;/a&gt; · &lt;a href=&quot;https://soundcloud.com/santiagorenteria/asturias-live-binaural-recording-contemporary-guitar-ensemble&quot; title=&quot;Asturias (Live Binaural Recording) - Contemporary Guitar Ensemble&quot; target=&quot;_blank&quot; style=&quot;color: #cccccc; text-decoration: none;&quot;&gt;Asturias (Live Binaural Recording) - Contemporary Guitar Ensemble&lt;/a&gt;&lt;/div&gt;
</description>
        <pubDate>Fri, 01 Sep 2017 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/renterialab.com/works/recording.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/works/recording.html</guid>
        
        <category>Audio Engineering</category>
        
        
        <category>works</category>
        
      </item>
    
      <item>
        <title>Ideology Diffusion Agent-based model</title>
        <description>&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/abm/1.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;Inspired by the concept of metacreation (the idea of endowing machines with creative behavior), I began exploring complex systems by taking a &lt;a href=&quot;https://www.complexityexplorer.org/courses/76-introduction-to-agent-based-modeling-summer-2017/certificates/483721217&quot;&gt;MOOC on Agent Based Modeling (ABM)&lt;/a&gt;. This field studies how systems composed of multiple individual elements (agents) interact with each other, and give rise to aggregate (emergent) properties that generally are not predictable from the elements themselves. In other words, in complex systems order can emerge without any design or designer (self-organization).&lt;/p&gt;

&lt;p&gt;Even though these kind of systems have been studied previously by using equation-based models and fractal theory, Agent Based Modeling makes the underlying mechanisms of complex systems explicit, in a way they can be understood by young children. In 1980 Papert confirmed this hypothesis by describing a turtle agent (from Logo language)) as a “body-syntonic” object: A user could project oneself into the turtle and, in order to figure out what commands it should be given, users could imagine what they would do with their bodies to achieve the desired effect. In this way ABMs are an intuitive representation of complex phenomena that are generally difficult to apprehend.&lt;/p&gt;

&lt;p&gt;The model I developed as a final project for the MOOC addresses the phenomenon of Ideology Difussion: How people decide which political viewpoint to adopt? Are people surrounded by those who share their same political viewpoint less likely to change theirs? What is the minimum number of influencers required for a person changing his political viewpoint (peer pressure)? On the other hand, in a system with multiple competing ideologies, does the system reach a balance (ideological segregation), or a dynamic equiliburm is established (of agents that continually change their ideology)? Can we relate the dynamics of this model to cultural segregation?&lt;/p&gt;

&lt;p&gt;I invite you to try the model and draw your own conclusions. You can download it &lt;a href=&quot;http://modelingcommons.org/browse/one_model/5264#model_tabs_browse_info&quot;&gt;here&lt;/a&gt;. Remember to install &lt;a href=&quot;https://ccl.northwestern.edu/netlogo/&quot;&gt;NetLogo&lt;/a&gt; first.&lt;/p&gt;
</description>
        <pubDate>Sun, 02 Jul 2017 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/renterialab.com/research/abm.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/research/abm.html</guid>
        
        <category>Multiagent Systems</category>
        
        <category>Computational Sociology</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>EmoSynth</title>
        <description>&lt;p&gt;During a Music technology hackaton (a 6 hour programming contest) I developed with two friends a Pure Data program for sonifying emotions through facial expressions. For this purpose we used &lt;a href=&quot;https://www.affectiva.com/&quot;&gt;Affectiva&lt;/a&gt;., a facial recognition API driven by Machine Learning. For more information please watch the video. And don’t forget turning on english subtitles. You can get the code &lt;a href=&quot;https://github.com/hermes2507/EmoSynth&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We got 1st place and won an Arturia MiniBrute Analog Synthesizer&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/emosynth/hackaton.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
</description>
        <pubDate>Sat, 01 Jul 2017 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/renterialab.com/works/emosynth.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/works/emosynth.html</guid>
        
        <category>Data Sonification</category>
        
        
        <category>works</category>
        
      </item>
    
      <item>
        <title>Automated Music Transcriptor</title>
        <description>&lt;p&gt;I was invited by professor &lt;a href=&quot;https://www.ericperezsegura.com/english&quot;&gt;Eric Pérez Segura&lt;/a&gt; to work in the development of a real time music transcription system for contemporary music. The work is still ongoing, but here I show the latest advances.&lt;/p&gt;

&lt;p&gt;Objectives&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generate hybrid graphical-regular scores in real time&lt;/li&gt;
  &lt;li&gt;Obtain specific algorithms for detecting musical patterns (v.g. thrills, clusters, etc.)&lt;/li&gt;
  &lt;li&gt;Create a new system for composition/improvisation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We took Eric’s notation and scores as a guide and defined a set of musical patterns to recognize using algorithms. Currently we are able to recognize trinos and chords, but in the future we expect to render these results in real time as graphical notation.&lt;/p&gt;

&lt;p&gt;Max was used as programming language together with javascript due to its realtime capabilities and ease for developing code snippets for individual musical patterns. Below are shown some examples of the graphical notation used by Eric. You can read the paper (draft) &lt;a href=&quot;https://www.researchgate.net/publication/315613918_Towards_an_Automatic_Music_Transcription_System_for_Contemporary_and_Experimental_Music_Languages_using_Non-Traditional_Music_Notation&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/mus_not/1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/mus_not/2.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/mus_not/3.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
</description>
        <pubDate>Fri, 02 Jun 2017 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/renterialab.com/research/music_not.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/research/music_not.html</guid>
        
        <category>Music</category>
        
        <category>AI</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Raspberry Pi Music Sequencer</title>
        <description>&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/rpi/beatstep.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;This project came out as a result of an internship with Arturia, a company specialized in the development of music software and hardware. I am currently in charge of developing open software for using the Raspberry Pi (and other development boards, like the BeagleBone + Bela) as an electronic musical instrument together with the Beatstep Pro (a MIDI sequencer) and other Arturia products. Programmed with Pure Data by Santiago Rentería and Miguel Moreno. See the demo videos below.&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe src=&quot;https://www.youtube.com/embed/0RgRyXR4a98&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe src=&quot;https://www.youtube.com/embed/ItS5SQTpcpk&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h1 id=&quot;how-does-it-work&quot;&gt;How does it work?&lt;/h1&gt;

&lt;p&gt;A set of samples is loaded to an SD card togheter with de Pure Data patch cointaining the sequencer. The Raspberry Pi (running Debian and connected to a DAC via I2C) is configured to launch the patch at startup on headless mode. Because the system should work in realtime I had to kill all unnecessary services consuming extra memory. Once the Beatstep Pro is conencted via USB to the Raspberry Pi MIDI communication is established and you can start playing. New samples can be added by uploading them to an USB drive in real time (or directly to the SD). Effect presets can be saved and shared. The system has a playback latency of 5 ms. Currently I am translating the code to run it on C++ in the Bela platform where latency is &amp;lt; 2 milliseconds.&lt;/p&gt;

&lt;p&gt;Test screen for checking if the patch is receiving input MIDI data from the Beatstep Pro.&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/rpi/test_screen.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;Programming blocks for each of the 16 samples of the sequencer/drumachine.&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/rpi/samples_mainscreen.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;ctlin objects route control MIDI messages coming from Beatstep Pro knobs. Playback speed, start and end times of each sample can be configured.&lt;/p&gt;

&lt;div class=&quot;8u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/rpi/sample_controls.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;You can apply effects (Filters, Bitcrusher, Delay, etc.) to each sample individually.&lt;/p&gt;

&lt;div class=&quot;8u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/rpi/EFX_controls.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 01 Jan 2017 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/renterialab.com/works/arturia.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/works/arturia.html</guid>
        
        <category>Music Technology</category>
        
        
        <category>works</category>
        
      </item>
    
      <item>
        <title>BCI for Playing Piano</title>
        <description>&lt;p&gt;During the &lt;a href=&quot;http://sitios.itesm.mx/novus/2015/convocatoria.html&quot;&gt;NOVUS 2015&lt;/a&gt; project, I had the opportunity to work with an interdisciplinary team on the development of a Brain-Computer Interface. This consisted in controlling a&lt;a href=&quot;https://inmoov.fr/&quot;&gt;3D printed arm&lt;/a&gt; via servo motors to play the piano. The team was made up by students from Systems Engineering, Mechatronics and Music Production Engineering. We published our paper &lt;a href=&quot;https://issuu.com/revistaheptagrama/docs/n4_completa/1?ff=true&quot;&gt;here&lt;/a&gt; (spanish).&lt;/p&gt;

&lt;p&gt;NOTE: The robotic arm yet could not move horizontally across the keyboard. Finger movement is achieved via facial gestures. We encourage others to implement more control gestures and make the interface more expressive.&lt;/p&gt;

&lt;div class=&quot;embed-container&quot;&gt;
  &lt;iframe src=&quot;https://www.youtube.com/embed/1Seg-Rklfcg&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
        <pubDate>Tue, 01 Nov 2016 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/renterialab.com/research/bci.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/research/bci.html</guid>
        
        <category>Mechatronics</category>
        
        <category>Signal Processing</category>
        
        <category>BCI</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Automatone</title>
        <description>&lt;p&gt;Inspired by Conway’s Game of Life I developed a music sequencer that plays notes whenever a cell is born inside a trigger (squares marked by colors). The notes are selected from a Pentatonic scale for avoiding dissonance. You can get the code &lt;a href=&quot;https://github.com/hermes2507/GameOfLifeMusic/tree/code&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/automatone/automatone.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
</description>
        <pubDate>Fri, 01 Jul 2016 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/renterialab.com/works/automatone.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/works/automatone.html</guid>
        
        <category>Music Technology</category>
        
        
        <category>works</category>
        
      </item>
    
      <item>
        <title>Machine Learning for Artists</title>
        <description>&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/ml_artists/cursotec.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;p&gt;As a part of the call for experimentation in education innovation: &lt;a href=&quot;http://sitios.itesm.mx/novus/2015/convocatoria.html&quot;&gt;NOVUS 2015&lt;/a&gt;, I received funding for giving a course of three modules about Machine Learning applied to digital arts. We explored the philosophical implications of AI in art, and the technical aspects for applying Machine Learning in Music and Interactive Art. The funding was used for buying various interfaces (&lt;a href=&quot;https://mashable.com/2015/05/24/myo-review/#gKp4E.ASo5qL&quot;&gt;Myo&lt;/a&gt;, &lt;a href=&quot;https://www.ultraleap.com/&quot;&gt;Leap Motion&lt;/a&gt;, &lt;a href=&quot;https://www.xbox.com/es-MX/xbox-one/accessories/kinect-for-xbox-one&quot;&gt;Kinect&lt;/a&gt; and &lt;a href=&quot;https://www.arduino.cc/&quot;&gt;Arduino&lt;/a&gt;) and &lt;a href=&quot;https://www.emotiv.com/&quot;&gt;Emotiv&lt;/a&gt; EEG sensors. Coursework materials can be found &lt;a href=&quot;http://cursomlsrenteria.blogspot.com/2016/03/presentaciones-del-curso.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;box alt&quot;&gt;
  &lt;div class=&quot;row uniform 50%&quot;&gt;
    &lt;div class=&quot;2u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&quot;8u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/ml_artists/posterTaller.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
    &lt;div class=&quot;2u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;/span&gt;&lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
</description>
        <pubDate>Tue, 01 Mar 2016 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/renterialab.com/research/ml_artists.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/research/ml_artists.html</guid>
        
        <category>Computational Creativity</category>
        
        <category>AI</category>
        
        
        <category>research</category>
        
      </item>
    
      <item>
        <title>Digital Audio Effects</title>
        <description>&lt;p&gt;This section contains various Digital Signal Processing algorithms implemented in the functional audio language &lt;a href=&quot;http://faust.grame.fr/&quot;&gt;Faust&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;binaural-shift&quot;&gt;Binaural Shift&lt;/h1&gt;

&lt;p&gt;An experimental effects processor for playing with two pitch shifted signals that pan periodically. Code &lt;a href=&quot;https://github.com/hermes2507/Binaural-shift/tree/faust_code&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/dsp/binaural.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;h1 id=&quot;voice-formant-synth&quot;&gt;Voice Formant synth&lt;/h1&gt;

&lt;p&gt;Implementation of formant synthesis for generating human-like (vocal synthesis). Code &lt;a href=&quot;https://github.com/hermes2507/FaustContest&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;8u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/dsp/dist.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;

&lt;h1 id=&quot;slicer--distortion&quot;&gt;Slicer + Distortion&lt;/h1&gt;

&lt;p&gt;A guitar effect with distortion and a slicer based on the interference of two pulse trains. Code &lt;a href=&quot;https://github.com/hermes2507/distortion-slicer/tree/code&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;div class=&quot;12u&quot;&gt;&lt;span class=&quot;image fit&quot;&gt;&lt;img src=&quot;/renterialab.com/images/dsp/voice.png&quot; alt=&quot;&quot; /&gt;&lt;/span&gt;&lt;/div&gt;
</description>
        <pubDate>Mon, 01 Jun 2015 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/renterialab.com/works/dsp.html</link>
        <guid isPermaLink="true">http://localhost:4000/renterialab.com/works/dsp.html</guid>
        
        <category>Audio programming</category>
        
        
        <category>works</category>
        
      </item>
    
  </channel>
</rss>
